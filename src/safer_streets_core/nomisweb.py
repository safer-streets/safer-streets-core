# based on code generated by datamodel-codegen:
#   filename:  top_level_geogs.json
#   timestamp: 2025-06-05T07:10:04+00:00

import os
from functools import cache
from hashlib import md5
from itertools import groupby
from pathlib import Path
from typing import Any

import pandas as pd
import requests
from dotenv import load_dotenv
from pydantic import BaseModel

from safer_streets_core.utils import data_dir


class AnnotationItem(BaseModel):
    annotationtext: int | str
    annotationtitle: str


class Annotations(BaseModel):
    annotation: list[AnnotationItem]


class Description(BaseModel):
    value: str
    lang: str


class CodeItem(BaseModel):
    annotations: Annotations = Annotations(annotation=[])
    description: Description
    value: int | str
    parentcode: int | None = None


class Name(BaseModel):
    value: str
    lang: str


class CodelistItem(BaseModel):
    agencyid: str
    id: str
    code: list[CodeItem]
    name: Name
    uri: str


class Codelists(BaseModel):
    codelist: list[CodelistItem]


class Contact(BaseModel):
    email: str
    name: str
    telephone: str | None
    uri: str


class Sender(BaseModel):
    contact: Contact
    id: str


class Header(BaseModel):
    id: str
    prepared: str
    sender: Sender
    test: str


class AttributeItem(BaseModel):
    assignmentstatus: str
    attachmentlevel: str
    codelist: str | None = None
    conceptref: str


class DimensionItem(BaseModel):
    codelist: str
    conceptref: str
    isfrequencydimension: str | None = None


class Primarymeasure(BaseModel):
    conceptref: str


class Timedimension(BaseModel):
    codelist: str
    conceptref: str


class Components(BaseModel):
    attribute: list[AttributeItem]
    dimension: list[DimensionItem]
    primarymeasure: Primarymeasure
    timedimension: Timedimension


class KeyfamilyItem(BaseModel):
    agencyid: str
    annotations: Annotations
    id: str
    components: Components
    name: Name
    uri: str
    version: float


class Keyfamilies(BaseModel):
    keyfamily: list[KeyfamilyItem]


class FieldStructure(BaseModel):
    codelists: Codelists
    header: Header
    xmlns: str
    common: str
    structure: str
    xsi: str
    schemalocation: str


class FieldMetadata(BaseModel):
    structure: FieldStructure

    # this is geography-specific
    def to_dataframe(self) -> pd.DataFrame:
        return pd.DataFrame(
            [
                {"NomisCode": item.value, "Description": item.description.value}
                | {a.annotationtitle: a.annotationtext for a in item.annotations.annotation}
                for item in self.structure.codelists.codelist[0].code
            ]
        ).set_index("NomisCode")


class TableStructure(BaseModel):
    header: Header
    keyfamilies: Keyfamilies
    xmlns: str
    common: str
    structure: str
    xsi: str
    schemalocation: str


class TableMetadata(BaseModel):
    structure: TableStructure


def build_geog_query(codes: list[int]) -> str:
    sequences = []
    for _key, group in groupby(enumerate(sorted(codes)), lambda item: item[1] - item[0]):
        items = list(group)  # Convert to list to easily access first and last elements
        start = items[0][1]  # The value of the first element in the group
        end = items[-1][1]  # The value of the last element in the group
        sequences.append(f"{start}...{end}" if start != end else f"{start}")
    return ",".join(sequences)


BASE_URL = "https://www.nomisweb.co.uk/api/v01"


@cache
def api_key() -> dict[str, str]:
    load_dotenv()
    return {"uid": os.environ["NOMIS_API_KEY"]}


def fetch(endpoint: str, **params: str) -> dict[str, Any]:
    response = requests.get(f"{BASE_URL}/{endpoint}", params=params | api_key())
    response.raise_for_status()
    return response.json()


def fetch_table(table_name: str, **params: str) -> pd.DataFrame:
    url = f"{BASE_URL}/dataset/{table_name}.data.csv?{'&'.join(f'{k}={v}' for k, v in (params | api_key()).items())}"
    # print(url)
    filename = Path(data_dir() / f"{md5(url.encode()).hexdigest()}.parquet")
    if not filename.exists():
        # headers = {"User-agent": "Mozilla/5.0"}
        data = pd.read_csv(url)  # storage_options=headers (if necessary)
        data.to_parquet(filename)
    else:
        data = pd.read_parquet(filename)
    return data
